# capsule_for_QQP

需要环境：tensorflow1.4，Python3.6，numpy，random，collections，csv

train.py文件是执行训练命令的脚本文件

model.py文件是模型构造主文件，该文件中编写了一个名为model的类，模型框架结构都在该类中被定义，包括输入变量，loss函数，acc函数，编码器，分类器等结构

function.py文件是自定义函数方法脚本文件，该文件中定义了在model中用到的一些函数方法，这些代码块功能相对独立，供外部引用文件使用，如fully_conacation，Dynamic_LSTM，con2D等

tool.py文件是数据预处理及读取数据文件，其中包括get_data,get_epoch,get_batch,read_file,load_vector,get_char等函数，同样的这个代码块功能相对单一，且相互独立，有些函数需要在网络运行之前预先进行处理，有些则是和网络一起运行，注意区分

config.py文件是用来预先定义超参数，如batch_size，embedding_size等，只能供别的脚本文件调用

使用该工程时，先使用tool.py文件里面的 get_data方法，支持使用相对路径以及绝对路径，建议使用相对路径，将数据集处理成index形式，方便模型直接读取。该代码涉及的步骤包括分词，统计词频，建立词典，将原文本映射成index形式，最后保存index文件。

接下来将train.py文件里的文件读取路径修改成自己的相对工程路径，直接运行train.py文件，网络会开始训练，如若需要读取已保存模型，只需将init_op注释掉，加上读取模型的代码即可继续训练。

# 1、任务描述

问题对相似度匹配任务算是自然语言处理领域比较热门的一个方向了，通过问题对的相似度计算，来用一个问题的答案去回答另一个问题，是自动问答领域的一个研究方向。
数据集形式是句子对加标签的形式给定，标签为0或者1，前者表示不相似，后者表示相似。通过模型的计算最后给出两个句子的相似概率，经过计算来判定两者相似或者不相似。

# 2、胶囊神经网络

胶囊——可以叫做向量神经元

之前的神经网络用的是标量神经元，只有大小没有方向，也就是说解决不了物体或者信息实体间的相对位置问题。

现在用一个向量神经元来表示一个实体的实例化或者一个属性。这样，向量的大小表示这个实体存在的概率，向量的方向就表示了这个实体的相对位置信息（或者叫方向信息，这里没有严格的概念定义，任务不同，定义不同）。

算法逻辑解释如下：

	第 1 行无需说明，唯一要指出的是迭代次数为 3 次，Hinton 在他论文里这样说道

	第 2 行初始化所有 b 为零，这是合理的。因为从第 4 行可看出，只有这样 c 才是均匀分布的，暗指“l 层 VN 到底要传送输出到 l+1 层哪个 VN 是最不确定的”

	第 4 行的 softmax 函数产出是非负数而且总和为 1，致使 c 是一组概率变量

	第 5 行的 sj 就是小节 2.3 第二步里面讲的红色簇心，可以认为是低层所有 VN 的“共识”输出

	第 6 行的 squash 确保向量 sj 的方向不变，但长度不超过 1，因为长度代表 VN 具有给定特征的概率

	第 7 行是动态路由的精华，用 Uj|i 和 vj 的点积 (dot product) 更新 bij，其中前者是 l 层 VNi对 l+1 层 VNj 的“个人”预测，而后者是所有 l 层 VN 对 l+1 层 VNj 的“共识”预测：

	当两者相似，点积就大，bij 就变大，低层 VNi 连接高层 VNj 的可能性就变大
	
	当两者相异，点积就小，bij 就变小，低层 VNi 连接高层 VNj 的可能性就变小

送入动态路由结构之前，要有胶囊与胶囊之间的矩阵变换，也就是，从低级实体到高级实体的时候，要有一个变换矩阵。称为姿态矩阵（在图像中），一方面是为了维度之间的契合，另一方面是从物理意义方面分析，高级实体由低级实体组成，姿态矩阵代表了前一级实体与高一级实体之间的组成（构成）关系。

最后输出的是向量，比如为分类问题，输出是N个向量，每个向量的长度代表了该类存在的概率。

# 3、模型创新点

1、采用胶囊网络，对于自然语言处理任务来说，这个结构具有天然的契合度，词嵌入的形式就是以一个向量为整体，输出可以是多个向量（对于多分类任务来说）。

2、将两个句子的相似度信息映射成一张图片，利用图片多重特征来实现网络的信息提取，这种做法具有先进性，目前已有很多这样的工作发表顶级论文。

3、编码器采用自我设计的co-dynamic_lstm，使得句子对在编码过程中充分交互信息。

# 4、结果

准确率88.2%，F1值89.9%
